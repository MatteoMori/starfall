 # Performance Tracking ğŸ“ˆ

Tracking qualitative + lightweight quantitative observations for local LLM performance in Starfall upgrade workflows.

> â„¹ï¸ No frontier (large proprietary) models yet due to cost & local-first preference. Starfall currently targets locally hosted models.

**Hardware (baseline test rig)**
* ğŸ§  CPU: Ryzen 7 (8 core)
* ğŸ’¾ Memory: 32 GB

## ğŸ† Current Best Model

For BOTH Kubernetes resource scanning and latest version discovery tasks the best overall balance of speed, accuracy, and token efficiency is:

â¡ï¸ **`qwen3:4b-instruct-2507-q4_K_M`**

Reasons:
* Fastest first-token + completion among tested variants
* Consistent extraction of required fields (including latest version labels)
* Lower memory footprint vs 8B while maintaining precision

---

## Test Run 1 (Context = 10,000)

**Generation Parameters:**
```dockerfile
PARAMETER num_ctx 10000
PARAMETER temperature 0.1
PARAMETER top_p 0.1
PARAMETER top_k 40
```

| Model | Perf Summary | Accuracy (qualitative) | Memory Footprint (approx) | Notes |
|-------|--------------|------------------------|----------------------------|-------|
| `qwen3:8b` | ğŸ¢ Slow (CPU saturated quickly) | N/A | High | Not ideal for rapid iterative tasks |
| `qwen3:4b-instruct` | Moderate | âœ… Perfect answer | Medium | Slight lag but reliable |
| `qwen3:4b-q8_0` | Moderate-slow | âš ï¸ Missed LATEST label | Medium-High (~12GB) | Retest after code improvements |
| `qwen3:4b-instruct-2507-q4_K_M` | ğŸš€ Fast | âœ… Perfect answer | Low/Lean | Chosen baseline going forward |

Legend: ğŸš€ = noticeably faster, ğŸ¢ = slow, âœ… = meets all extraction goals, âš ï¸ = partial/missing field

---

## ğŸ¯ Next Experiments

Objective: Evaluate impact of reducing context window to 4096 on latency & output completeness.

| Model | Planned num_ctx | Hypothesis | Priority |
|-------|-----------------|-----------|----------|
| `qwen3:4b-instruct` | 4096 | Should speed up slightly; accuracy intact | High |
| `qwen3:4b-q8_0` | 4096 | May still miss labelsâ€”validate after parser improvements | Medium |
| `qwen3:4b-instruct-2507-q4_K_M` | 4096 | Expect same accuracy, even faster â†’ candidate default | High |
| `qwen3:8b` | 4096 | Still too slow; baseline comparative data | Low |
| `qwen3:8b-q8_0` | 4096 | Check if quantization narrows gap vs 4B variants | Medium |


---

## ğŸ“Œ Notes & Actions
* Re-run `qwen3:4b-q8_0` after improving label extraction logic.

